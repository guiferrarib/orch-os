// SPDX-License-Identifier: MIT OR Apache-2.0
// Copyright (c) 2025 Guilherme Ferrari Brescia

/**
 * LiveTranscriptionProcessor handles processing of transcription data from Deepgram
 * and management of speaker segments.
 */
import { Logger } from '../utils/Logger';
import { SpeakerBuffer } from '../utils/DeepgramTypes';

// Import of the interface for integration with the transcription storage service
import { ITranscriptionStorageService } from '../../interfaces/transcription/ITranscriptionStorageService';

export class LiveTranscriptionProcessor {
  private logger: Logger;
  private activeSpeakerBuffer: Record<number, SpeakerBuffer> = {};
  private currentSpeaker: string = '';
  private transcriptionList: string[] = [];
  private transcriptionCallback: ((event: string, data: any) => void) | null = null;
  private transcriptionStorageService: ITranscriptionStorageService | null = null;
  
  constructor() {
    this.logger = new Logger('LiveTranscriptionProcessor');
  }
  
  /**
   * Configures the transcription storage service for direct sending
   */
  public setTranscriptionStorageService(service: ITranscriptionStorageService): void {
    console.log(`üíæ [INTEGRATION] Storage service received:`, service ? "VALID INSTANCE" : "NULL");
    this.transcriptionStorageService = service;
    if (service && typeof service.updateTranscriptionUI === 'function') {
      console.log(`‚úÖ [INTEGRATION] updateTranscriptionUI available and ready for use`);
    } else {
      console.error(`‚ùå [INTEGRATION] updateTranscriptionUI NOT available!`, service);
    }
    this.logger.info("Storage service configured for direct sending");
  }
  
  /**
   * Register a callback to receive transcription events
   */
  public registerTranscriptionCallback(callback: (event: string, data: any) => void): void {
    this.transcriptionCallback = callback;
    this.logger.info("Callback registered");
  }
  
  /**
   * Process incoming transcription data from Deepgram
   */
  public handleTranscriptionEvent(data: any): void {
    try {
      console.log("üîÑ [PROCESS] Starting transcription processing");
      
      // Check if this is a final transcription
      // We ignore all interim (non-final) transcriptions
      if (!data.is_final) {
        console.log("‚è≠Ô∏è [PROCESS] Ignoring interim (non-final) transcription");
        return;
      }
      
      // Check if data contains channel (singular) or channels (plural)
      if (data.channel) {
        // New Deepgram API (v3)
        const channelIndex = data.channel_index && data.channel_index[0] !== undefined
          ? data.channel_index[0]
          : 0;

        console.log(`üîÑ [PROCESS] Processing channel ${channelIndex}`);

        // Initialize buffer for this channel if not exists
        if (!this.activeSpeakerBuffer[channelIndex]) {
          console.log(`üîÑ [PROCESS] Initializing buffer for channel ${channelIndex}`);
          this.activeSpeakerBuffer[channelIndex] = {
            lastSpeaker: channelIndex === 0 ? "Guilherme" : `Speaker ${channelIndex}`,
            currentSegment: [],
            formattedSegment: '',
            lastFlushedText: ""
          };
        }

        const alternative = data.channel.alternatives[0];
        if (!alternative?.transcript) {
          console.log("‚ùå [PROCESS] Alternative without transcription, aborting");
          return;
        }
        
        const buffer = this.activeSpeakerBuffer[channelIndex];
        const speakerPrefix = (this.currentSpeaker !== buffer.lastSpeaker) 
          ? `[${buffer.lastSpeaker}] ` 
          : "";

        console.log(`üîÑ [PROCESS] Current speaker: "${this.currentSpeaker}", Buffer speaker: "${buffer.lastSpeaker}"`);
        console.log(`üîÑ [PROCESS] Speaker prefix: "${speakerPrefix}"`);

        // Update current speaker
        this.currentSpeaker = buffer.lastSpeaker;
        
        // Process the transcript content immediately
        const transcriptText = `${speakerPrefix}${alternative.transcript}`;
        console.log(`üîÑ [PROCESS] Formatted text: "${transcriptText}"`);
        
        // Check if this is new or different content
        if (transcriptText && transcriptText.trim() && 
            transcriptText !== buffer.lastFlushedText && 
            transcriptText.trim() !== `[${buffer.lastSpeaker}]`) {
          
          console.log(`‚úÖ [PROCESS] Valid and different text: "${transcriptText}"`);
          this.logger.info(`Final transcription (channel ${channelIndex}): ${transcriptText}`);
          
          // Send only final transcriptions directly via IPC to the main process
          // Explicitly check the storage service for each transcription
          try {
            if (this.transcriptionStorageService) {
              // Ensure the method exists before calling
              if (typeof this.transcriptionStorageService.updateTranscriptionUI === 'function') {
                console.log(`üìù [PROCESS] Sending directly to TranscriptionStorageService: "${transcriptText}"`);
                this.transcriptionStorageService.updateTranscriptionUI(transcriptText);
                console.log(`‚úÖ [PROCESS] Transcription successfully sent to storageService`);
              } else {
                console.error(`‚ùå [PROCESS] updateTranscriptionUI NOT available in service!`);
              }
            } else {
              console.warn(`‚ö†Ô∏è [PROCESS] TranscriptionStorageService NOT available during transcription processing`);
            }
          } catch (error) {
            console.error(`‚ùå [PROCESS] Error sending to TranscriptionStorageService:`, error);
          }
          
          // Maintain IPC sending for compatibility with panel
          if (typeof window !== 'undefined' && window.electronAPI) {
            try {
              console.log(`üì¢ [PROCESS] Sending final transcription via IPC: "${transcriptText}"`);
              window.electronAPI.sendAudioTranscription(transcriptText);
            } catch (error) {
              console.error("‚ùå [PROCESS] Error sending via IPC:", error);
            }
          }
          
          // Also send via callback for compatibility
          if (this.transcriptionCallback) {
            console.log(`üì¢ [PROCESS] Sending to callback: "${transcriptText}"`);
            this.transcriptionCallback("transcript", {
              text: transcriptText,
              isFinal: true, // Always true because we're filtering out non-final transcriptions
              channel: channelIndex,
              speaker: buffer.lastSpeaker
            });
          } else {
            console.log("‚ùå [PROCESS] TranscriptionCallback NOT registered");
          }
          
          // Add to permanent history
          console.log(`üìù [PROCESS] Saving final transcription: "${transcriptText}"`);
          this.transcriptionList.push(transcriptText);
          buffer.lastFlushedText = transcriptText;
        } else {
          console.log(`‚ö†Ô∏è [PROCESS] Text ignored because it was empty or the same as the previous: "${transcriptText}"`);
        }
        
        // Store the formatted version
        buffer.formattedSegment = alternative.transcript;
        
        // Still accumulate words for speaker change detection
        if (alternative.words && alternative.words.length > 0) {
          console.log(`üîÑ [PROCESS] Processing ${alternative.words.length} words for speaker detection`);
          buffer.currentSegment = alternative.words.map((w: { word: any }) => w.word);

          // Process speaker changes in words if available
          let currentSegmentSpeaker = buffer.lastSpeaker;
          for (const word of alternative.words) {
            if (word.speaker) {
              const speaker = `Speaker ${word.speaker}`;
              if (speaker !== currentSegmentSpeaker) {
                // Speaker change detected
                console.log(`üë• [PROCESS] Speaker change detected: ${currentSegmentSpeaker} -> ${speaker}`);
                this.logger.info(`Speaker change detected: ${currentSegmentSpeaker} -> ${speaker}`);
                currentSegmentSpeaker = speaker;
                buffer.lastSpeaker = speaker;
              }
            }
          }
        } else {
          console.log("‚ö†Ô∏è [PROCESS] No words for speaker detection");
        }
      } else if (data.channels) {
        console.log(`üîÑ [PROCESS] Multichannel mode, processing ${data.channels.length} channels`);
        // Simplified processing for multiple channels
        data.channels.forEach((channel: any, channelIndex: number) => {
          console.log(`üîÑ [PROCESS] Processing channel ${channelIndex}`);
          
          // Initialize buffer for this channel if not exists
          if (!this.activeSpeakerBuffer[channelIndex]) {
            console.log(`üîÑ [PROCESS] Initializing buffer for channel ${channelIndex}`);
            this.activeSpeakerBuffer[channelIndex] = {
              lastSpeaker: channelIndex === 0 ? "Guilherme" : `Speaker ${channelIndex}`,
              currentSegment: [],
              formattedSegment: '',
              lastFlushedText: ""
            };
          }

          const alternative = channel.alternatives[0];
          if (!alternative?.transcript) {
            console.log(`‚ùå [PROCESS] Channel ${channelIndex} without transcription, skipping`);
            return;
          }
          
          const buffer = this.activeSpeakerBuffer[channelIndex];
          const transcriptText = `[${buffer.lastSpeaker}] ${alternative.transcript}`;
          console.log(`üîÑ [PROCESS] Text of channel ${channelIndex}: "${transcriptText}"`);
          
          // Send final transcriptions via IPC to the main process
          if (typeof window !== 'undefined' && window.electronAPI && 
              transcriptText.trim() && transcriptText !== buffer.lastFlushedText) {
            try {
              console.log(`üì¢ [PROCESS] Sending final transcription via IPC: "${transcriptText}"`);
              // Use the new method to send transcriptions
              window.electronAPI.sendAudioTranscription(transcriptText);
            } catch (error) {
              console.error("‚ùå [PROCESS] Error sending via IPC:", error);
            }
          }
          
          // Also send via callback for compatibility
          if (this.transcriptionCallback && transcriptText.trim() && 
              transcriptText !== buffer.lastFlushedText) {
            
            console.log(`üì¢ [PROCESS] Sending to callback: "${transcriptText}"`);
            this.transcriptionCallback("transcript", {
              text: transcriptText,
              isFinal: true, // Always true because we're filtering out non-final transcriptions
              channel: channelIndex,
              speaker: buffer.lastSpeaker
            });
            
            // Save final transcription
            console.log(`üìù [PROCESS] Saving final transcription: "${transcriptText}"`);
            this.transcriptionList.push(transcriptText);
            buffer.lastFlushedText = transcriptText;
          } else {
            console.log(`‚ö†Ô∏è [PROCESS] Text ignored: empty=${!transcriptText.trim()}, repeated=${transcriptText === buffer.lastFlushedText}`);
          }
          
          // Store formatted version
          buffer.formattedSegment = alternative.transcript;
        });
      } else {
        console.log("‚ùå [PROCESS] Unrecognized data format:", Object.keys(data));
      }
       
      console.log("‚úÖ [PROCESS] Transcription processing completed");
    } catch (error) {
      console.log("‚ùå [PROCESS] Error during transcription processing:", error);
      this.logger.error("Error processing transcription", error);
    }
  }
  
  /**
   * Flush the current speaker segment and return formatted text
   */
  public flushSpeakerSegment(channelIndex: number): string | null {
    const buffer = this.activeSpeakerBuffer[channelIndex];
    if (!buffer || buffer.currentSegment.length === 0) return null;

    // Use the original formatted text instead of reconstructing from words
    const content = buffer.formattedSegment || buffer.currentSegment.join(' ').trim();
    if (!content) return null;
    
    // Check if speaker has changed from last transcription segment
    const speakerPrefix = (this.currentSpeaker !== buffer.lastSpeaker) 
      ? `[${buffer.lastSpeaker}] ` 
      : "";
    
    // Update current speaker
    this.currentSpeaker = buffer.lastSpeaker;
    
    const text = `${speakerPrefix}${content}`;
    buffer.currentSegment = [];
    buffer.formattedSegment = '';
    return text;
  }
  
  /**
   * Get the stored transcription list
   */
  public getTranscriptionList(): string[] {
    return [...this.transcriptionList];
  }
  
  /**
   * Clear the transcription history
   */
  public clearTranscriptionList(): void {
    this.transcriptionList = [];
  }
}
